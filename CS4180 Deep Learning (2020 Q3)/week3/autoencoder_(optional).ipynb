{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a folder to save output images\n",
    "if not os.path.exists('./mlp_img'):\n",
    "    os.mkdir('./mlp_img')\n",
    "\n",
    "# a function used to transform numpy array to image format\n",
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x\n",
    "\n",
    "#################### select your hyperparameters ############################\n",
    "num_epochs = \n",
    "batch_size = \n",
    "learning_rate = \n",
    "\n",
    "####### define image transforms, you can have other choices, explore it! #####\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# download MNIST dataset\n",
    "dataset = MNIST('./data', transform=img_transform, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define autoencoder\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(True), \n",
    "            nn.Linear(128, 32))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 28 * 28), \n",
    "            nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the model to be the autoencoder defined above\n",
    "model = autoencoder()\n",
    "############ chose appropriate loss function ######################\n",
    "criterion = \n",
    "\n",
    "# set the optimizer, explore the effect of different optimizers\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/20], loss:0.0755\n",
      "epoch [2/20], loss:0.0493\n",
      "epoch [3/20], loss:0.0468\n",
      "epoch [4/20], loss:0.0409\n",
      "epoch [5/20], loss:0.0384\n",
      "epoch [6/20], loss:0.0378\n",
      "epoch [7/20], loss:0.0373\n",
      "epoch [8/20], loss:0.0369\n",
      "epoch [9/20], loss:0.0332\n",
      "epoch [10/20], loss:0.0331\n",
      "epoch [11/20], loss:0.0330\n",
      "epoch [12/20], loss:0.0383\n",
      "epoch [13/20], loss:0.0329\n",
      "epoch [14/20], loss:0.0323\n",
      "epoch [15/20], loss:0.0310\n",
      "epoch [16/20], loss:0.0302\n",
      "epoch [17/20], loss:0.0326\n",
      "epoch [18/20], loss:0.0318\n",
      "epoch [19/20], loss:0.0285\n",
      "epoch [20/20], loss:0.0349\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        img, _ = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        img = Variable(img)\n",
    "        # ===================forward=====================\n",
    "        output = model(img)\n",
    "        loss = criterion(output, img)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================user interaction========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, loss.data))\n",
    "    if epoch % 1 == 0:\n",
    "        pic = to_img(output.data)\n",
    "        save_image(pic, './mlp_img/image_{}.png'.format(epoch))\n",
    "        \n",
    "        ori_pic = to_img(img.data)\n",
    "        save_image(ori_pic, './mlp_img/ori_image_{}.png'.format(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
